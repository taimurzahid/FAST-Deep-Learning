{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1000 Images Done\n",
      "Progress: 2000 Images Done\n",
      "Progress: 3000 Images Done\n",
      "Progress: 4000 Images Done\n",
      "Progress: 5000 Images Done\n",
      "Progress: 6000 Images Done\n",
      "Progress: 7000 Images Done\n",
      "Progress: 8000 Images Done\n",
      "Progress: 9000 Images Done\n",
      "Progress: 10000 Images Done\n",
      "Progress: 11000 Images Done\n",
      "Progress: 12000 Images Done\n",
      "Progress: 13000 Images Done\n",
      "Progress: 14000 Images Done\n",
      "Progress: 15000 Images Done\n",
      "Progress: 16000 Images Done\n",
      "Progress: 17000 Images Done\n",
      "Progress: 18000 Images Done\n",
      "Progress: 19000 Images Done\n",
      "Progress: 20000 Images Done\n",
      "Progress: 21000 Images Done\n",
      "Progress: 22000 Images Done\n",
      "Progress: 23000 Images Done\n",
      "Progress: 24000 Images Done\n",
      "Progress: 25000 Images Done\n",
      "25000\n",
      "25000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 3)         30        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 10)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 31, 31, 3)         273       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 31, 31, 5)         380       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 10)          210       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 490)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 490)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               49100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 50,374\n",
      "Trainable params: 50,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(25000, 64, 64)\n",
      "(25000, 64, 64, 1)\n",
      "(25000,)\n",
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      "17500/17500 [==============================] - 158s 9ms/step - loss: 0.6106 - acc: 0.7026 - val_loss: 1.1244 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "17500/17500 [==============================] - 149s 8ms/step - loss: 0.5963 - acc: 0.7143 - val_loss: 1.1559 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "17500/17500 [==============================] - 149s 9ms/step - loss: 0.5815 - acc: 0.7134 - val_loss: 0.9526 - val_acc: 0.1415\n",
      "Epoch 4/10\n",
      "17500/17500 [==============================] - 149s 8ms/step - loss: 0.5607 - acc: 0.7233 - val_loss: 1.2537 - val_acc: 0.1043\n",
      "Epoch 5/10\n",
      "11136/17500 [==================>...........] - ETA: 44s - loss: 0.5447 - acc: 0.7387"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,MaxPooling2D,Conv2D,Flatten,Dropout\n",
    "%matplotlib inline\n",
    "\n",
    "train = 'C:\\\\Users\\\\Grace\\\\Downloads\\\\Compressed\\\\all\\\\train\\\\train\\\\'\n",
    "test = 'C:\\\\Users\\\\Grace\\\\Downloads\\\\Compressed\\\\all\\\\test\\\\test\\\\'\n",
    "\n",
    "data = []\n",
    "test_data = []\n",
    "test_id = []\n",
    "label = []\n",
    "im_width = 64\n",
    "im_height = 64\n",
    "train_image_files = [ f for f in os.listdir(train) if os.path.isfile(os.path.join(train,f)) ]\n",
    "test_image_files = [ f for f in os.listdir(test) if os.path.isfile(os.path.join(test,f)) ]\n",
    "\n",
    "image_file = str(train + train_image_files[5])\n",
    "img = cv2.imread(image_file)\n",
    "plt.imshow(img)\n",
    "\n",
    "image_file = str(train + train_image_files[17000])\n",
    "img = cv2.imread(image_file)\n",
    "plt.imshow(img)\n",
    "\n",
    "image_file = str(train + train_image_files[8000])\n",
    "img = cv2.imread(image_file)\n",
    "plt.imshow(img)\n",
    "\n",
    "image_file = str(train + train_image_files[22000])\n",
    "img = cv2.imread(image_file)\n",
    "plt.imshow(img)\n",
    "\n",
    "# Grayscale for easy processing\n",
    "image_file = str(train + train_image_files[24])\n",
    "img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE) # read a grayscale image\n",
    "plt.imshow(img, cmap='gray') # show a grayscale image\n",
    "\n",
    "def preprocessing(path):\n",
    "    progress = 0\n",
    "    image_files = [ f for f in os.listdir(path) if os.path.isfile(os.path.join(path,f)) ]\n",
    "    \n",
    "    for file in image_files:\n",
    "        image_file = str(path + file)\n",
    "        \n",
    "        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img)\n",
    "        new_img = cv2.resize(img, (im_width, im_height))\n",
    "        plt.imshow(new_img)\n",
    "        \n",
    "        if file[:3] == 'cat':\n",
    "            label.append(0)\n",
    "            data.append(new_img / 255)\n",
    "            \n",
    "        elif file[:3] == 'dog':\n",
    "            label.append(1)\n",
    "            data.append(new_img / 255)\n",
    "        \n",
    "        progress = progress + 1\n",
    "        if progress % 1000 == 0:\n",
    "            plt.imshow(img)\n",
    "            print('Progress: ' + str(progress) + ' Images Done')\n",
    "        \n",
    "    print(len(data))\n",
    "    print(len(label))    \n",
    "    \n",
    "    \n",
    "preprocessing(train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(kernel_size=(3,3),filters=3,input_shape=(im_width, im_height, 1),activation=\"relu\",padding=\"valid\"))\n",
    "model.add(Conv2D(kernel_size=(3,3),filters=10,activation=\"relu\",padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(kernel_size=(3,3),filters=3,activation=\"relu\",padding=\"same\"))\n",
    "model.add(Conv2D(kernel_size=(5,5),filters=5,activation=\"relu\",padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "model.add(Conv2D(kernel_size=(2,2),strides=(2,2),filters=10))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(100,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "    \n",
    "model.compile(optimizer='adadelta',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "\n",
    "# Converting it into a Tensor\n",
    "data = data.reshape((data.shape)[0], (data.shape)[1], (data.shape)[2], 1)\n",
    "print(data.shape)\n",
    "\n",
    "label = np.array(label)\n",
    "print(label.shape)\n",
    "\n",
    "model.fit(data, label, batch_size=64, epochs=10, verbose=1, validation_split=0.3 )\n",
    "\n",
    "model.save(\"C:\\\\Users\\\\Grace\\\\Downloads\\\\Compressed\\\\keras_model_attempt_1.h5\")\n",
    "\n",
    "#model = load_model(\"G:/Dogs vs. Cats/keras_model_attempt_1.h5\")\n",
    "\n",
    "def preprocessing_test(path):\n",
    "    progress = 0\n",
    "    \n",
    "    for file in test_image_files:\n",
    "        image_file = str(path + file)\n",
    "        \n",
    "        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        new_img = cv2.resize(img, (im_width, im_height))\n",
    "        \n",
    "        test_id.append(file[:-4])\n",
    "        test_data.append(new_img / 255)\n",
    "        \n",
    "        progress = progress + 1\n",
    "        if progress % 1000 == 0:\n",
    "            print('Progress: ' + str(progress) + ' Images Done')\n",
    "        \n",
    "    print(len(test_data))\n",
    "    print(len(test_id))    \n",
    "preprocessing_test(test)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "print(test_data.shape)\n",
    "\n",
    "test_data = test_data.reshape((test_data.shape)[0], (test_data.shape)[1], (test_data.shape)[2], 1)\n",
    "print(test_data.shape)\n",
    "\n",
    "predicted_labels = model.predict(test_data)\n",
    "\n",
    "final_labels = []\n",
    "for value in predicted_labels:\n",
    "    if value > 0.5:\n",
    "        final_labels.append(1)\n",
    "    else:\n",
    "        final_labels.append(0)\n",
    "final_submission = pd.DataFrame({\"id\" : test_id })\n",
    "\n",
    "final_submission[\"label\"] = final_labels\n",
    "\n",
    "final_submission.info()\n",
    "\n",
    "final_submission.head()\n",
    "\n",
    "final_submission.to_csv(\"C:\\\\Users\\\\Grace\\\\Downloads\\\\Compressed\\\\CatsandDogs\\\\first_attempt_cnn_keras.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
